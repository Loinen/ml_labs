{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ml_lab6.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYsMHtyE-SY4"
      },
      "source": [
        "# ПОСТРОЕНИЕ ПРЕДСКАЗАТЕЛЬНОЙ МОДЕЛИ ВОЗНИКНОВЕНИЯ ИНСУЛЬТА"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uDaYQuO-SY8"
      },
      "source": [
        "В этой лабораторной работе вам потребуется выбрать наилучший классификатор с оптимальными параметрами для задачи про пассажиров \"Титаника\" -- \n",
        "В данной работе будет построена предсказательная модель возникновения инсульта на основе данных о [пациентах](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) c kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgI_NOXe-SY9"
      },
      "source": [
        "1. Загрузка данных и библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGjOXIIc-SZA"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "train = pd.read_csv(\"train.csv\") # lab5_input\n",
        "test = pd.read_csv(\"test.csv\") # lab5_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzESnbVq-SZB"
      },
      "source": [
        "2. Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygn9Cotl-SZC"
      },
      "source": [
        "def process_age(df, cut_points, label_names):\n",
        "    df['Age'] = df['Age'].replace(np.NaN, -0.5) #fillna\n",
        "    df['Age_categories'] = pd.cut(df['Age'], bins=cut_points, labels=label_names)\n",
        "    return df\n",
        "\n",
        "cut_points = [-1, 0, 5, 12, 18, 35, 60, 100]\n",
        "label_names = [\"Missing\", \"Infant\", \"Child\", \"Teenager\", \"Young_Adult\", \"Adult\", \"Senior\"]\n",
        "train = process_age(train, cut_points, label_names)\n",
        "test = process_age(test, cut_points, label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g59lM_RVkD2l"
      },
      "source": [
        "def create_dummies(df, column_name):\n",
        "    dum = pd.get_dummies(df[column_name], prefix=[column_name])\n",
        "    df = pd.concat([df,dum],axis=1)\n",
        "    return df\n",
        "\n",
        "train = create_dummies(train, \"Pclass\")\n",
        "test = create_dummies(test, \"Pclass\")\n",
        "\n",
        "train = create_dummies(train, \"Sex\")\n",
        "test = create_dummies(test, \"Sex\")\n",
        "\n",
        "train = create_dummies(train, \"Age_categories\")\n",
        "test = create_dummies(test, \"Age_categories\")\n",
        "\n",
        "#train = create_dummies(train, \"Embarked\")\n",
        "#test = create_dummies(test, \"Embarked\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocej4tPp-SZD"
      },
      "source": [
        "__Задание 3.__  \n",
        "Примените масштабирование признаков (`StandardScaler`, `MinMaxScaler`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_ToXzV-SZE"
      },
      "source": [
        "drop_cols = ['Name', 'Sex', 'PassengerId', 'Age', 'Age_categories', 'Ticket', 'Cabin', 'Embarked', 'Pclass']\n",
        "drop_cols = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age',\n",
        "                 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Age_categories'] \n",
        "train = train.drop(columns=drop_cols, axis=1)\n",
        "test = test.drop(columns=drop_cols, axis=1)\n",
        "#print(train[train.isnull().any(axis=1)])\n",
        "\n",
        "#features = ['Parch', 'SibSp', 'Fare']\n",
        "#train[features]= MinMaxScaler().fit_transform(train[features])\n",
        "#test[features]= MinMaxScaler().fit_transform(test[features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZylz7X-SZE"
      },
      "source": [
        "__Задание 4.__  \n",
        "Примените различные преобразования признаков (`PolynomialFeatures`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuXKuP4_-SZG"
      },
      "source": [
        "\n",
        "tpoly = PolynomialFeatures(degree=3, interaction_only=True)\n",
        "tpoly3 = tpoly.fit_transform(train)\n",
        "\n",
        "fpoly = PolynomialFeatures(degree=3, interaction_only=False)\n",
        "fpoly3 = fpoly.fit_transform(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLSt8MmV-SZH"
      },
      "source": [
        "__Задание 5.__  \n",
        "Обучите несколько классификаторов, в том числе:  \n",
        "1. Логистическую регрессию (`LogisticRegression`).\n",
        "1. Метод опорных векторов (`SVC`).\n",
        "1. Метод *k* ближайших соседей (`KNeighborsClassifier`).\n",
        "1. Наивный байесовский классификатор (`MultinomialNB`).\n",
        "1. Деревья решений (`DecisionTreeClassifier`).\n",
        "1. Случайный лес (`RandomForestClassifier`).\n",
        "1. AdaBoost (`AdaBoost`).\n",
        "1. Градиентный бустинг (`GradientBoostingClassifier`).\n",
        "\n",
        "Для обучения и проверки качества можно использовать функцию `train_test_split()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdYM2lOyyIzR",
        "outputId": "f33c22f9-7b50-40df-aeda-8122cb042c12"
      },
      "source": [
        "y = train['Survived']\n",
        "df = train.copy()\n",
        "df = df.drop(['Survived'], axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, y, train_size=0.8, random_state=42)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(712, 12) (179, 12) (712,) (179,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTfbnlicyszm",
        "outputId": "1c93848d-3fcb-4cf0-ef61-668fd609e537"
      },
      "source": [
        "# Логистическая регрессия\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(x_train, y_train) \n",
        "y_pred = lr.predict(x_test)\n",
        "print(lr.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8044692737430168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiz_YG-ZyxEj",
        "outputId": "98a320bc-f913-4baa-ba2d-d22c8301b4df"
      },
      "source": [
        "# Метод опорных векторов (SVC)\n",
        "svc = SVC(random_state=42)\n",
        "svc.fit(x_train, y_train)\n",
        "print(svc.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8156424581005587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRO8X7lIyxMl",
        "outputId": "986facca-4416-42c7-ef00-a8b75265960c"
      },
      "source": [
        "# Метод k ближайших соседей (KNeighborsClassifier)\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(x_train, y_train)\n",
        "print(knn.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8100558659217877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XZL0xBhyxYL",
        "outputId": "ef3303c9-4851-42a1-a40e-1fb4d424c880"
      },
      "source": [
        "# Наивный байесовский классификатор (MultinomialNB)\n",
        "gaussian = MultinomialNB()\n",
        "gaussian.fit(x_train, y_train)\n",
        "print(gaussian.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.770949720670391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UWMi3Uvyxep",
        "outputId": "2ffa3c41-c69e-4b68-8bab-01a4ed059a3c"
      },
      "source": [
        "# Деревья решений (DecisionTreeClassifier)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(x_train, y_train)\n",
        "print(decision_tree.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8044692737430168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQiXvuaEy-Ta",
        "outputId": "e0466238-d68c-4bd2-b6be-ddb51e6f8a6e"
      },
      "source": [
        "# Случайный лес (RandomForestClassifier)\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(x_train, y_train)\n",
        "print(random_forest.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8044692737430168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6TvjzVFy_sR",
        "outputId": "f30abb95-4eae-4ea1-a94b-f35b0e03c7a6"
      },
      "source": [
        "# AdaBoost (AdaBoost)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "ada.fit(x_train, y_train)\n",
        "print(ada.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8044692737430168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDDKSGEozBQP",
        "outputId": "3d5cbdf8-d2a3-4a6a-ee4f-d9de4d51459e"
      },
      "source": [
        "# Градиентный бустинг (GradientBoostingClassifier)\n",
        "gbc = GradientBoostingClassifier(random_state=42).fit(x_train, y_train)\n",
        "print(gbc.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8100558659217877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP2sHlpM-SZJ"
      },
      "source": [
        "__Задание 6.__  \n",
        "При помощи `Pipeline` и `GridSearchCV` выберите оптимальную архитектуру:\n",
        "1. Метод масштабирования.\n",
        "1. Степень полинома в `PolynomialFeatures`.\n",
        "1. Параметры классификаторов (в том числе, параметры регуляризации).\n",
        "\n",
        "Заносите в таблицу Excel результаты тестирования (варианты параметров, оценки качества)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yj2cJq2lRgW"
      },
      "source": [
        "\n",
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    SVC(),\n",
        "    KNeighborsClassifier(),\n",
        "    MultinomialNB(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "    ]\n",
        "\n",
        "# LogisticRegression()\n",
        "params1 = {\"poly__degree\": range(1,4,1), \"clf__solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
        "           \"clf__max_iter\": range(700,1000,100)} # range start stop step\n",
        "# SVC\n",
        "params2 = {\"poly__degree\": range(1,4,1),\"clf__kernel\":[\"rbf\", \"poly\", \"linear\", \"sigmoid\"], \"clf__gamma\": [\"auto\", \"scale\"], \"clf__degree\":range(1,6,1)}\n",
        "# KNeighborsClassifier()\n",
        "params3 = {\"poly__degree\": range(1,4,1),\"clf__n_neighbors\": range(5,10,2), \"clf__weights\": [\"uniform\", \"distance\"],\n",
        "         \"clf__algorithm\": ['ball_tree', 'kd_tree']}\n",
        "# MultinomialNB()\n",
        "params4 = {\"poly__degree\": range(1,4,1),\"clf__fit_prior\": ['True', 'False'], \"clf__alpha\": [0.5,0.3,0.1]}\n",
        "# DecisionTreeClassifier()\n",
        "params5 = {\"poly__degree\": range(1,4,1),\"clf__criterion\":[\"gini\", \"entropy\"], \"clf__max_depth\": range(2,30,3), \"clf__min_samples_split\": [2,3],\n",
        "           \"clf__min_samples_leaf\": range(1,10,3)}   \n",
        "# RandomForestClassifier()\n",
        "params6 = {\"poly__degree\": range(1,4,1),\"clf__criterion\":[\"gini\", \"entropy\"], \"clf__class_weight\":[\"balanced\", \"balanced_subsample\"], \n",
        "           \"clf__max_depth\": range(4,10,2), \"clf__min_samples_leaf\": [1,2,5], \"clf__n_estimators\":range(50,150,50)} \n",
        "# AdaBoostClassifier()\n",
        "params7 = {\"poly__degree\": range(3,6,1),\"clf__learning_rate\":np.arange(0.3,0.7,0.1), \"clf__n_estimators\":range(20,60,20),\n",
        "         \"clf__algorithm\":[\"SAMME\", \"SAMME.R\"]} \n",
        "# GradientBoostingClassifier()\n",
        "params8 = {\"poly__degree\": range(3,5,1),\"clf__loss\":[\"deviance\", \"exponential\"], \n",
        "           \"clf__learning_rate\":[0.08,0.07,0.075], \"clf__n_estimators\":range(60,120,20),\n",
        "           \"clf__min_samples_leaf\": range(1,4,1), \"clf__max_depth\": range(1,4,1), \n",
        "           \"clf__max_features\": [\"auto\", \"sqrt\", \"log2\"], \"clf__validation_fraction\":np.arange(0.01,0.2,0.05)}\n",
        "\n",
        "\n",
        "parameters = [params1, params2, params3, params4, params5, params6, params7, params8]\n",
        "i = 0\n",
        "for classifier in classifiers:\n",
        "    print(classifier)\n",
        "    pipe = Pipeline(steps=[('scaler', MinMaxScaler()), #MinMaxScaler() StandardScaler()\n",
        "                            ('poly', PolynomialFeatures()),\n",
        "                            ('clf', classifier) # , return_train_score = True\n",
        "                      ])\n",
        "    grid_cv = model_selection.GridSearchCV(pipe, parameters[i], scoring='accuracy')\n",
        "    grid_cv.fit(x_train, y_train)\n",
        "    print(\"model best score: \", grid_cv.best_score_)    \n",
        "    print(grid_cv.best_params_)\n",
        "    model = grid_cv.best_estimator_\n",
        "    print(\"model test score: \", model.score(x_test, y_test))\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBYihCsN-SZK"
      },
      "source": [
        "__Задание 7.__  \n",
        "1. Выберите несколько лучших классификаторов (от 3 до 10).\n",
        "1. Обучите выбранные классификаторы на всех доступных размеченных данных.\n",
        "1. Получите результаты предсказания для тестовых данных.\n",
        "1. Отправьте результаты на сервер [Kaggle](https://ru.wikipedia.org/wiki/Титаник)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unNr1_U3-SZL",
        "outputId": "8aaff0b2-713d-4863-f6aa-f4636c911a7a"
      },
      "source": [
        "y = train['Survived']\n",
        "df = train.copy()\n",
        "df = df.drop(['Survived'], axis=1)\n",
        "test2 = pd.read_csv(\"test.csv\") \n",
        "test_ids = test2[\"PassengerId\"]\n",
        "\n",
        "# RandomForestClassifier()\n",
        "rfc = {\"poly__degree\": range(1,4,1),\"clf__criterion\":[\"gini\", \"entropy\"], \"clf__class_weight\":[\"balanced\", \"balanced_subsample\"], \n",
        "           \"clf__max_depth\": range(2,5,1), \"clf__min_samples_leaf\": [1,2,3], \"clf__n_estimators\":range(50,150,50)} \n",
        "pipe = Pipeline(steps=[     ('scaler', StandardScaler()), #MinMaxScaler() StandardScaler()\n",
        "                            ('poly', PolynomialFeatures()),\n",
        "                            ('clf', RandomForestClassifier()) \n",
        "                      ])\n",
        "grid_cv = model_selection.GridSearchCV(pipe, rfc, scoring='accuracy')\n",
        "grid_cv.fit(df, y)\n",
        "print(\"model best score: \", grid_cv.best_score_)    \n",
        "print(grid_cv.best_params_)\n",
        "model = grid_cv.best_estimator_\n",
        "\n",
        "test_predictions = model.predict(test)\n",
        "\n",
        "submission_df = {\"PassengerId\": test_ids,\n",
        "                 \"Survived\": test_predictions}\n",
        "\n",
        "submission = pd.DataFrame(submission_df)\n",
        "submission.to_csv('titanic_submission_rf.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model best score:  0.8080911430544223\n",
            "{'clf__class_weight': 'balanced_subsample', 'clf__criterion': 'entropy', 'clf__max_depth': 3, 'clf__min_samples_leaf': 2, 'clf__n_estimators': 50, 'poly__degree': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4lDfOuwrGiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f70708f-96fc-4aa8-b1ee-f1596cf26f88"
      },
      "source": [
        "# AdaBoostClassifier()\n",
        "ada = {\"poly__degree\": range(1,5,1),\"clf__learning_rate\":np.arange(0.3,0.7,0.1), \"clf__n_estimators\":range(10,50,10),\n",
        "         \"clf__algorithm\":[\"SAMME\", \"SAMME.R\"]} \n",
        "pipe = Pipeline(steps=[     ('scaler', MinMaxScaler()), #MinMaxScaler() StandardScaler()\n",
        "                            ('poly', PolynomialFeatures()),\n",
        "                            ('clf', AdaBoostClassifier()) \n",
        "                      ])        \n",
        "grid_cv = model_selection.GridSearchCV(pipe, ada, scoring='accuracy')\n",
        "grid_cv.fit(df, y)\n",
        "print(\"model best score: \", grid_cv.best_score_)    \n",
        "print(grid_cv.best_params_)\n",
        "model = grid_cv.best_estimator_\n",
        "\n",
        "test_predictions = model.predict(test)\n",
        "\n",
        "submission_df = {\"PassengerId\": test_ids,\n",
        "                 \"Survived\": test_predictions}\n",
        "\n",
        "submission = pd.DataFrame(submission_df)\n",
        "submission.to_csv('titanic_submission_ada.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model best score:  0.8002761910740066\n",
            "{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.5, 'clf__n_estimators': 20, 'poly__degree': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_aqIHqUrGzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c007ea6-7ac9-4088-c872-f4a90297cd94"
      },
      "source": [
        "# GradientBoostingClassifier()\n",
        "gb = {\"poly__degree\": [2,3],\"clf__loss\":[\"deviance\", \"exponential\"], \n",
        "           \"clf__learning_rate\":[0.05,0.06], \"clf__n_estimators\":[20,30],\n",
        "           \"clf__min_samples_leaf\": [1,2], \"clf__max_depth\": [3,4]}\n",
        "\n",
        "pipe = Pipeline(steps=[     ('scaler', StandardScaler()), #MinMaxScaler() StandardScaler()\n",
        "                            ('poly', PolynomialFeatures()),\n",
        "                            ('clf', GradientBoostingClassifier()) \n",
        "                      ])\n",
        "grid_cv = model_selection.GridSearchCV(pipe, gb, scoring='accuracy')\n",
        "grid_cv.fit(df, y)\n",
        "print(\"model best score: \", grid_cv.best_score_)    \n",
        "print(grid_cv.best_params_)\n",
        "model = grid_cv.best_estimator_\n",
        "\n",
        "test_predictions = model.predict(test)\n",
        "\n",
        "submission_df = {\"PassengerId\": test_ids,\n",
        "                 \"Survived\": test_predictions}\n",
        "\n",
        "submission = pd.DataFrame(submission_df)\n",
        "submission.to_csv('titanic_submission_gb.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model best score:  0.8024982738057874\n",
            "{'clf__learning_rate': 0.05, 'clf__loss': 'exponential', 'clf__max_depth': 3, 'clf__min_samples_leaf': 2, 'clf__n_estimators': 20, 'poly__degree': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
